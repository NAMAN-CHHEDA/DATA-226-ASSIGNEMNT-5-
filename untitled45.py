# -*- coding: utf-8 -*-
"""Untitled45.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h5AmLnul3o4m5xitqx9aN82GVgewQ-mB
"""

# dags/assignment5_stock_prices.py
from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task
from datetime import datetime, timedelta, timezone
from typing import List, Dict  # keep Py3.8+ compatible typing
import requests
import snowflake.connector


# ---- Snowflake helper --------------------------------------------------------
def _snowflake_cursor():
    # Validate Variables early so failures are obvious in task logs
    required_vars = [
        "snowflake_userid",
        "snowflake_password",
        "snowflake_account",
        "snowflake_database",
        "snowflake_warehouse",
    ]
    missing = [v for v in required_vars if not Variable.get(v, default_var=None)]
    if missing:
        raise ValueError(f"Missing Airflow Variables: {', '.join(missing)}")

    user_id = Variable.get("snowflake_userid")
    password = Variable.get("snowflake_password")
    account = Variable.get("snowflake_account")
    database = Variable.get("snowflake_database")
    warehouse = Variable.get("snowflake_vwh")
    role = Variable.get("role")

    # Open connection with explicit session context; autocommit off so we control txns
    conn = snowflake.connector.connect(
        user=user_id,
        password=password,
        account=account,          # e.g. xy12345.us-east-1
        warehouse=warehouse,
        database=database,
        role=role,
        autocommit=False,
    )
    cur = conn.cursor()
    cur.execute(f"USE ROLE {role}")
    cur.execute(f"USE WAREHOUSE {warehouse}")
    cur.execute(f"USE DATABASE {database}")
    return conn, cur


# ---- DAG ---------------------------------------------------------------------
with DAG(
    dag_id="assignment5",
    start_date=datetime(2025, 10, 1),
    schedule="30 2 * * *",
    catchup=False,
    tags=["ETL", "stocks"],
) as dag:

    SYMBOL = Variable.get("stock_symbol", default_var="GOOG")
    TARGET_SCHEMA = "RAW"
    TARGET_TABLE = "ASSIGNMENT_5"

    @task
    def ensure_objects():
        ddl_schema = f"CREATE SCHEMA IF NOT EXISTS {TARGET_SCHEMA}"
        ddl_table = f"""
        CREATE TABLE IF NOT EXISTS {TARGET_SCHEMA}.{TARGET_TABLE} (
          SYMBOL VARCHAR(10) NOT NULL,
          DATE   DATE        NOT NULL,
          OPEN   FLOAT       NOT NULL,
          CLOSE  FLOAT       NOT NULL,
          HIGH   FLOAT       NOT NULL,
          LOW    FLOAT       NOT NULL,
          VOLUME INTEGER     NOT NULL,
          PRIMARY KEY (SYMBOL, DATE)
        )
        """
        conn, cur = _snowflake_cursor()
        try:
            # If your role cannot create schemas, pre-create RAW once and comment the next line.
            cur.execute(ddl_schema)
            cur.execute(ddl_table)
            conn.commit()
            print(f"Ensured {TARGET_SCHEMA}.{TARGET_TABLE} exists.")
        except Exception as e:
            conn.rollback()
            # Optional: richer error output
            try:
                from snowflake.connector.errors import Error as SFError
                if isinstance(e, SFError):
                    print(f"Snowflake error: sqlstate={e.sqlstate}, errno={e.errno}, msg={e.msg}")
            except Exception:
                pass
            raise
        finally:
            cur.close()
            conn.close()

    @task
    def extract_prices(symbol: str, days: int = 90) -> List[Dict]:
        api_key = Variable.get("vantage_api_key")
        if not api_key:
            raise ValueError("Missing Airflow Variable: 'vantage_api_key'")

        url = (
            "https://www.alphavantage.co/query"
            f"?function=TIME_SERIES_DAILY&symbol={symbol}"
            f"&outputsize=compact&datatype=json&apikey={api_key}"
        )
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        data = r.json()

        # Alpha Vantage throttle note or error
        if "Time Series (Daily)" not in data:
            raise RuntimeError(f"Alpha Vantage response error: {data}")

        series = data["Time Series (Daily)"]
        cutoff = (datetime.now(timezone.utc) - timedelta(days=days)).date()

        rows: List[Dict] = []
        for d_str, vals in series.items():
            d = datetime.strptime(d_str, "%Y-%m-%d").date()
            if d >= cutoff:
                rows.append({
                    "symbol": symbol.upper(),
                    "date":   d,  # Python date (binds cleanly to Snowflake DATE)
                    "open":   float(vals["1. open"]),
                    "high":   float(vals["2. high"]),
                    "low":    float(vals["3. low"]),
                    "close":  float(vals["4. close"]),
                    "volume": int(vals["5. volume"]),
                })

        rows.sort(key=lambda r: r["date"])  # oldest â†’ newest
        return rows

    @task
    def load_prices_idempotent(rows: List[Dict]):
        """
        Load via a session TEMP table (unqualified) then MERGE into RAW.ASSIGNMENT5.
        Using an unqualified TEMP table avoids needing CREATE privilege on RAW for the stage.
        """
        if not rows:
            print("No rows to load.")
            return

        conn, cur = _snowflake_cursor()
        try:
            cur.execute("BEGIN")

            # IMPORTANT: no schema qualifier for TEMP table
            cur.execute("""
                CREATE TEMP TABLE IF NOT EXISTS ASSIGNMENT5_STAGE (
                    SYMBOL VARCHAR(10),
                    DATE   DATE,
                    OPEN   FLOAT,
                    CLOSE  FLOAT,
                    HIGH   FLOAT,
                    LOW    FLOAT,
                    VOLUME INTEGER
                )
            """)
            cur.execute("DELETE FROM ASSIGNMENT5_STAGE")

            insert_sql = """
                INSERT INTO ASSIGNMENT5_STAGE
                (SYMBOL, DATE, OPEN, CLOSE, HIGH, LOW, VOLUME)
                VALUES (%(symbol)s, %(date)s, %(open)s, %(close)s, %(high)s, %(low)s, %(volume)s)
            """
            cur.executemany(insert_sql, rows)

            merge_sql = f"""
                MERGE INTO {TARGET_SCHEMA}.{TARGET_TABLE} t
                USING ASSIGNMENT5_STAGE s
                ON t.SYMBOL = s.SYMBOL AND t.DATE = s.DATE
                WHEN MATCHED THEN UPDATE SET
                    OPEN = s.OPEN,
                    CLOSE = s.CLOSE,
                    HIGH = s.HIGH,
                    LOW = s.LOW,
                    VOLUME = s.VOLUME
                WHEN NOT MATCHED THEN INSERT (SYMBOL, DATE, OPEN, CLOSE, HIGH, LOW, VOLUME)
                VALUES (s.SYMBOL, s.DATE, s.OPEN, s.CLOSE, s.HIGH, s.LOW, s.VOLUME)
            """
            cur.execute(merge_sql)
            conn.commit()
        except Exception as e:
            conn.rollback()
            try:
                from snowflake.connector.errors import Error as SFError
                if isinstance(e, SFError):
                    print(f"Snowflake error: sqlstate={e.sqlstate}, errno={e.errno}, msg={e.msg}")
            except Exception:
                pass
            raise
        finally:
            cur.close()
            conn.close()

    # wiring
    ensure = ensure_objects()
    data = extract_prices(SYMBOL)
    ensure >> load_prices_idempotent(data)

